#!/usr/bin/env python3.8

import glob
import os
import sys
import json
import subprocess
import tempfile
import shutil

ROOT_OF_FILES="backend/static/"
BUCKET="gs://darklang-static-assets"

# Gather list of files in known dir
allStaticFiles = [f for f in glob.glob(ROOT_OF_FILES + '**', recursive=True) if os.path.isfile(f)]


# Filter out files we don't care about
def shouldCopyFile(filename):
  filesToSkip = [ROOT_OF_FILES + ".gitkeep", ROOT_OF_FILES + "etags.json"]
  if filename in filesToSkip:
    return False

  if filename.endswith(".gz") or filename.endswith(".br"):
    return False

  return True
staticFilesToCopy = [f for f in allStaticFiles if shouldCopyFile(f)]


# We want to call `gsutil cp` in bulk by Content-Type shortly, but it doesn't
# support a way to copy multiple files in one call while also renaming them.
# So, we copy files to a new temp dir, adjusting file names to have hashes
# injected where relevant.
tempDir = tempfile.gettempdir() + "/static-assets/"
shutil.rmtree(tempDir, ignore_errors=True)

with open(ROOT_OF_FILES + '/etags.json', 'r') as f:
  etags = json.load(f)

def shouldHash(filename):
  return not filename.startswith("vendor/")

def getRemoteFileName(filePath):
  filePath = filePath.replace(ROOT_OF_FILES, '')

  if shouldHash(filePath):
    fileHash = etags[filePath]
    (base, _dot, extension) = filePath.rpartition('.')
    return f'{base}-{fileHash}.{extension}'
  else:
    return filePath

def getRemoteFilePath(filename):
  return tempDir + getRemoteFileName(filename)

for f in staticFilesToCopy:
  target = getRemoteFilePath(f)
  os.makedirs( os.path.dirname(target), exist_ok=True)
  shutil.copy(f, target)

# from now on, we don't care about the original paths
staticFilesToCopy = [getRemoteFilePath(f) for f in staticFilesToCopy]
ROOT_OF_FILES = tempDir


# Determine content-type / mimetype
# See also ApiServer.configureStaticContent
def mimeTypeFor(filename):
  # Common web stuff
  if filename.endswith(".css"): return "text/css"
  elif filename.endswith(".js"): return "application/javascript"
  elif filename.endswith(".json"): return "application/json"
  elif filename.endswith(".txt"): return "text/plain"
  elif filename.endswith(".png"): return "image/png"
  elif filename.endswith(".svg"): return "image/svg+xml"
  elif filename.endswith(".html"): return "text/html"
  # Fonts
  elif filename.endswith(".ttf"): return "font/ttf"
  elif filename.endswith(".woff"): return "font/woff"
  elif filename.endswith(".woff2"): return "font/woff2"
  elif filename.endswith(".eot"): return "application/vnd.ms-fontobject"
  # Blazor
  elif filename.endswith(".wasm"): return "application/wasm"
  elif filename.endswith(".pdb"): return "text/plain"
  elif filename.endswith(".dll"): return "application/octet-stream"
  elif filename.endswith(".dat"): return "application/octet-stream"
  elif filename.endswith(".blat"): return "application/octet-stream"
  else:
    # Don't allow anything else
    print(f'Unknown extension for {filename}')
    sys.exit(-1)


# Group the files to copy by the Content-Type we want to send it as
# key = mimetype, value = list of static file (by local name)
filesGroupedByMimetype = {}
for f in staticFilesToCopy:
  mimetype = mimeTypeFor(f)

  if mimetype in filesGroupedByMimetype:
    filesGroupedByMimetype[mimetype].append(f)
  else:
    filesGroupedByMimetype[mimetype] = [f]

# Copy the files to CDN - one `gsutil cp` call per Content-Type
for mimetype in filesGroupedByMimetype:
  filesToCopy = " ".join(filesGroupedByMimetype[mimetype])

  # Prepare a `gsutil cp` call
  # -h: set header
  # -Z: Uploaded file is served as zipped. Also adds 'no-transform' to Cache-Control header
  # -n: Don't overwrite
  # -m: Upload assets in parallel, within call
  gsutilCommand = ''' gsutil \
    -h "Content-Type:{mimetype}" \
    -h "Cache-Control:public" \
    cp -Z -n {files} "{remoteDir}"
    '''.format(mimetype=mimetype, files=filesToCopy, remoteDir=BUCKET)

  subprocess.run(gsutilCommand, shell=True)

# Wrap up
shutil.rmtree(tempDir, ignore_errors=True)
print("Done!")