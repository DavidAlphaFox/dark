#!/usr/bin/env python3

# Script to manage deployment of kubernetes services

# See description in services/README.md

import os
import sys

if os.getenv("IN_DEV_CONTAINER") != "true":
  print("Must be run in dev container")
  sys.exit(1)

import argparse
import collections
import glob
import jsonschema
import os.path
import re
import subprocess
import yaml
import json

##################################
# definitions
##################################
REGION = "us-west1"
PROJECT = "balmy-ground-195100"
CLUSTER = "$(< current-cluster)"
CLUSTER_CONFIGMAP_FILE = "config/gke-builtwithdark"
CLOUDSQL_INSTANCE_NAME = "dark-west"
DEPLOY_LOCK_BUCKET = "gs://darklang-deploy-lock"

##################################
# Utility functions
##################################


def bad(str):
  print(str)
  sys.exit(1)


should_debug = False
should_dry_run = False


def debug(str):
  if should_debug:
    print("DEBUG: ", str)


def readfile(filename):
  with open(filename, "r") as f:
    return f.read()


def writefile(filename, contents):
  with open(filename, "w") as f:
    f.write(contents)


# Run an important command, keeping stdout/stderr going to the user. Supports --dry-run
def run(name, args, shell=False, input=None):
  try:
    if should_dry_run:
      print(f"Running {name} command: (dry-run)\n  {args}")
    else:
      print(f"Running {name} command:\n  {args}")
      subprocess.run(args, shell=shell, input=input, check=True)
      print()
  except subprocess.CalledProcessError as e:
    bad(f"Error running {name} command:\n  {e}\n")


# Runs a command that's part of running the script, captures stdout, ignore --dry-run.
def run_output(args, shell=False, input=None):
  try:
    debug(f"Running command:\n  {args}")
    return subprocess.check_output(args, shell=shell,
                                   input=input).decode("utf-8").strip()
  except subprocess.CalledProcessError as e:
    bad(f"Error running command:\n  {e}\n")


##################################
# Assertions
##################################


def assert_file_exists(dir, f):
  if not os.path.exists(os.path.join(dir, f)):
    bad(f"File {dir}/{f} does not exist")


def assert_dir_exists(service, d):
  if not os.path.exists(d):
    bad(f"Directory {d} does not exist")


def assert_string_in_file(filename, file_str, substr):
  if substr not in file_str:
    bad(f"String missing from {filename}: {substr}")


##################################
# Load services / config
##################################
def get_service_dirs(args):
  dirs = args.services
  if dirs == []:
    dirs = [path for path in glob.glob(r'services/**') if "README.md" not in path]
  elif len(dirs) == 1 and dirs[0].endswith("deploy.yaml"):
    dirs = [os.path.dirname(dirs[0])]
  sorted_dirs = sorted(dirs)
  return sorted_dirs


def get_service_config(dir):
  try:
    file = open(dir + "/deploy.yaml")
  except:
    bad(f"Missing config file in {dir}/deploy.yaml")
  try:
    return yaml.load(file, Loader=yaml.Loader)
  except Exception as e:
    bad(f"Bad yaml in {dir}/deploy.yaml\n  {e}")


##################################
# Config commands
##################################


def get_all_config_file_arguments(args):
  files = []
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    for f in config['k8s']["manually-deployed-config"]["configs"]:
      files.append(os.path.join(dir, f))

  file_args = []
  for f in files:
    file_args.append("-f")
    file_args.append(f)
  return file_args


def config_diff(args):
  do_validation(args)

  # Diff files
  file_args = get_all_config_file_arguments(args)
  if file_args == []:
    debug("No files to diff, skipping")
  else:
    run("kubectl diff", ["kubectl", "diff"] + file_args)

  # Custom diffs
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    for c in config['k8s']["manually-deployed-config"].get("custom-diff", []):
      run("custom diff", c, shell=True)


def config_apply_manually(args):
  args.services = [args.service]
  do_validation(args)

  # Apply files
  file_args = get_all_config_file_arguments(args)
  if file_args == []:
    debug("No files to apply, skipping")
  else:
    run("kubectl apply", ["kubectl", "apply"] + file_args)

  # Custom apply
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    for c in config['k8s']["manually-deployed-config"].get("custom-apply", []):
      run("custom apply", c, shell=True)

  # Custom post-apply (used for restarting services)
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    for c in config['k8s']["manually-deployed-config"].get("custom-post-apply", []):
      run("custom post apply", c, shell=True)


##################################
# Container commands
##################################


def get_service_containers(args):
  needed_containers = set()
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    containers = config['k8s'].get("deployment", {"containers": []})["containers"]
    for c in containers:
      needed_containers.add(c)
  return needed_containers


def containers_list(args):
  do_validation(args)
  status = run_output(["docker", "image", "ls"]).split("\n")
  service_containers = get_service_containers(args)
  for line in status:
    for c in service_containers:
      if c in line:
        print(line)
        break


def containers_show_manifest(args):
  do_validation(args)
  output = {}
  for c in get_service_containers(args):
    url = f"gcr.io/{PROJECT}/{c}"
    id = run_output(["docker", "images", url, "-q"]).split("\n")[0]
    output[c] = id
  print(json.dumps(output, indent=2))


def containers_pull(args):
  print("Pulling, if error you might need `gcloud auth configure-docker`")
  do_validation(args)
  for c in get_service_containers(args):
    image = f"gcr.io/{PROJECT}/{c}:latest"
    run("docker pull", ["docker", "pull", image])


def containers_push(args):
  print("Pushing, if error you might need `gcloud auth configure-docker`")
  do_validation(args)

  def image_info(c):
    image_id = run_output([f"docker images -q {c} | head -n 1"], shell=True)
    url = f"gcr.io/{PROJECT}/{c}"
    return type('', (object, ), {
        'image': f"{url}:{image_id}",
        'image_latest': f"{url}:latest"
    })()

  for c in get_service_containers(args):
    info = image_info(c)
    run("docker tag id", ["docker", "tag", f"{c}:latest", info.image])
    run("docker tag latest", ["docker", "tag", f"{c}:latest", info.image_latest])

  for c in get_service_containers(args):
    info = image_info(c)
    run("docker push", ["docker", "push", info.image])
    run("docker push", ["docker", "push", info.image_latest])


def containers_build(args):
  do_validation(args)
  commitSha = run_output(["git", "rev-parse", "--short", "HEAD"])

  def build_container(name, dockerfilename):
    print(f"building {name} docker image")
    dockerfile = readfile(dockerfilename)
    run("docker build", [
        "docker", "build", "--tag", f"{name}:latest", "--build-arg",
        f"GIT_COMMIT={commitSha}", "-"
    ],
        input=dockerfile.encode("utf-8"))

  build_container("dark-base-service", "containers/base-service-Dockerfile")
  build_container("dark-ocaml-service", "containers/ocaml-service-Dockerfile")
  build_container("dark-fsharp-service", "containers/fsharp-service-Dockerfile")

  # Each container name represents a container in containers/. If there's a prep.sh
  # file in the dir, run it first and then build the container in the directory it
  # echos. If there is no dockerfile, then do nothing (sometimes we use vendor
  # containers and so we just need to store config files).
  for c in get_service_containers(args):
    dir = os.path.join("containers", c)
    if os.path.isdir(dir) and os.path.exists(os.path.join(dir, "Dockerfile")):
      print(f"\nBuild container {c}")
      prep = os.path.join(dir, "prep.sh")
      if os.path.exists(prep):
        dir = run_output(prep)
      run("docker build", [
          "docker", "build", "--tag", f"{c}:latest", "--build-arg",
          f"GIT_COMMIT={commitSha}", dir
      ])
    else:
      print(f"\nNo dockerfile, skipping {c}")


##################################
# Deployments
##################################
def get_expected_args(args):
  expected_args = {}
  for arg in args.args or []:
    items = arg.strip().split("=")
    k = items[0].strip()
    v = "=".join(items[1:]).strip()
    if (v.startswith("\"") and v.endswith("\"")) or \
       (v.startswith("'") and v.endswith("'")):
      v = v[1:-1]
    expected_args[k] = v
  return expected_args


def generate_manifests(args):
  builtins = {"CLOUDSQL_INSTANCE_NAME": CLOUDSQL_INSTANCE_NAME}
  expected_args = get_expected_args(args)
  files = []
  ids = json.load(open(args.manifest))
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    deployment = config['k8s'].get("deployment")
    if deployment:
      filename = os.path.join(dir, deployment["config-template"])

      # Fill in the blanks
      content = readfile(filename)
      for c in deployment["containers"]:
        content = content.replace(f"{{IMAGEID:{c}}}", ids[c])
      for a in deployment["expected-args"]:
        value = expected_args.get(a)
        if value == None:
          bad(f"No value provided for `ARG:{a}. Pass it at the command line using `--args {a}='SOME VALUE'`"
              )
        content = content.replace(f"{{ARG:{a}}}", expected_args[a])
      for v in deployment.get("builtins", []):
        content = content.replace(f"{{BUILTIN:{v}}}", builtins[v])

      # Write the non-template version
      target_filename = filename.replace(".template", "")
      writefile(target_filename, content)
      files.append(target_filename)
  return files


def deployment_diff(args):
  do_validation(args)
  files = generate_manifests(args)

  # diff it against production
  if files == []:
    debug("No files to diff, skipping")
  else:
    file_args = ["kubectl", "diff"]
    for f in files:
      file_args.append("-f")
      file_args.append(f)
    run("kubectl diff", file_args)


def deployment_dry_run(args):
  do_validation(args)
  files = generate_manifests(args)

  # diff it against production
  if files == []:
    debug("No files to apply, skipping")
  else:
    file_args = []
    for f in files:
      file_args.append("-f")
      file_args.append(f)
    run("kubectl apply --dry-run=client",
        ["kubectl", "apply", "--dry-run=client"] + file_args)
    run("kubectl apply --dry-run=client",
        ["kubectl", "apply", "--dry-run=server"] + file_args)


##################################
# Validate config files
##################################

config_schema = """
type: object
properties:
  k8s:
    type: object
    properties:
      manually-deployed-config:
        type: object
        properties:
          configs:
            type: array
            items:
              type: string
          custom-diff:
            type: array
            items:
              type: string
          custom-apply:
            type: array
            items:
              type: string
        required: [configs]
        additionalProperties: false
      deployment:
        type: object
        properties:
          config-template:
            type: string
          containers:
            type: array
            items:
              type: string
          expected-args:
            type: array
            items:
              type: string
          builtins:
            type: array
            items:
              type: string
        required: [containers, config-template]
        additionalProperties: false
    required: [manually-deployed-config]
    additionalProperties: false
"""


def do_validation(args):
  for dir in get_service_dirs(args):
    config = get_service_config(dir)
    debug(f"Validating config for {dir}")
    try:
      jsonschema.validate(config, yaml.load(config_schema, Loader=yaml.Loader))
    except jsonschema.exceptions.ValidationError as e:
      bad(f"Error in {dir}/deploy.yaml:\n  {e}")

    k8s = config['k8s']

    manually_deployed_config = k8s["manually-deployed-config"]
    configs = manually_deployed_config["configs"]
    for f in configs:
      assert_file_exists(dir, f)

    deployment = config['k8s'].get("deployment", None)
    if deployment:
      assert_file_exists(dir, deployment['config-template'])
      template_filename = os.path.join(dir, deployment['config-template'])
      template_contents = open(template_filename).read()

      for c in deployment["containers"]:
        assert_dir_exists(dir, f"containers/{c}")
        # Check the containers are used in the template
        assert_string_in_file(template_filename, template_contents,
                              f"{{IMAGEID:{c}}}")

      # Check the vars are used in the template
      for var in deployment.get("builtins", []):
        assert_string_in_file(template_filename, template_contents,
                              f"{{BUILTIN:{var}}}")
      for var in deployment.get("expected-args", []):
        assert_string_in_file(template_filename, template_contents, f"{{ARG:{var}}}")

      # Check all template vars are defined
      for match in re.findall(r"\{([-A-Z0-9a-z:_]+)}", template_contents,
                              re.MULTILINE):
        builtin_match = re.match(r"^BUILTIN:([A-Z0-9_]+)$", match)
        expectedarg_match = re.match(r"^ARG:([A-Z0-9_]+)$", match)
        imageid_match = re.match(r"^IMAGEID:([-a-z0-9]+)$", match)
        if builtin_match:
          builtin = builtin_match.group(1)
          if builtin not in deployment["builtins"]:
            bad(f"builtin \"{builtin}\" not in `k8s.deployment.builtins` in\n{template_filename}"
                )

        elif expectedarg_match:
          expectedarg = expectedarg_match.group(1)
          if expectedarg not in deployment["expected-args"]:
            bad(f"expected arg \"{expectedarg}\" not in `k8s.deployment.expected-args` in\n{template_filename}"
                )

        elif imageid_match:
          id = imageid_match.group(1)
          if id not in deployment["containers"]:
            bad(f"imageid \"{id}\" not in `k8s.deployment.containers` in\n{template_filename}"
                )
        else:
          bad(f"Unexpected placeholder \"{{{match}}}\" in\n{template_filename}")


def validate(args):
  do_validation(args)
  print("All deploy.yaml files successfully validated")


##################################
# Argument parser
##################################


def create_arg_parser():
  # The base parser has the commands shared by ALL subcommands
  base_parser = argparse.ArgumentParser(add_help=False)
  base_parser.add_argument('--debug',
                           action='store_true',
                           help="Print debug info about what's running")
  base_parser.add_argument(
      '--dry-run',
      action='store_true',
      help="paths to the service definitions. Leave empty to run on all services")
  base_parser.set_defaults(debug=False)
  base_parser.set_defaults(dry_run=False)

  # We want to be explicit about listing services for side-effecting commands
  services_parser = argparse.ArgumentParser(add_help=False)
  services_parser.add_argument(
      'services',
      action="store",
      nargs="*",
      help=
      "paths to the service definitions (directories within services/). Leave empty to run on all services"
  )

  main_parser = argparse.ArgumentParser(
      description='Manage deployment of kubernetes services')
  main_subparsers = main_parser.add_subparsers()

  # Validate
  validate_parser = main_subparsers.add_parser(
      'validate',
      description="Validates deploy.yaml files",
      parents=[base_parser, services_parser])
  validate_parser.set_defaults(func=validate)

  # Config
  config_parser = main_subparsers.add_parser('config')
  config_subparser = config_parser.add_subparsers()

  config_diff_parser = config_subparser.add_parser(
      'diff',
      description=
      "Checks that the config files listed in the k8s.manually-deployed-config key of deploy.yaml are already properly deployed, using `kubectl diff`",
      parents=[base_parser, services_parser])
  config_diff_parser.set_defaults(func=config_diff)

  config_apply_parser = config_subparser.add_parser(
      'apply-manually',
      description=
      "Checks that the config files listed in the k8s.manually-deployed-config key of deploy.yaml are already properly deployed, using `kubectl diff`",
      parents=[base_parser])
  config_apply_parser.add_argument(
      'service',
      action="store",
      help=
      "path to the service definition. Required and only one service is supported")
  config_apply_parser.set_defaults(func=config_apply_manually)

  # Containers
  containers_parser = main_subparsers.add_parser('containers')
  containers_subparser = containers_parser.add_subparsers()

  containers_build_parser = containers_subparser.add_parser(
      'build',
      description="Builds the container images needed by services",
      parents=[base_parser, services_parser])
  containers_build_parser.set_defaults(func=containers_build)

  containers_pull_parser = containers_subparser.add_parser(
      'pull',
      description="Pull the remote docker images used by services",
      parents=[base_parser, services_parser])
  containers_pull_parser.set_defaults(func=containers_pull)

  containers_push_parser = containers_subparser.add_parser(
      'push',
      description="Push local docker images used by services to gcr",
      parents=[base_parser, services_parser])
  containers_push_parser.set_defaults(func=containers_push)

  containers_list_parser = containers_subparser.add_parser(
      'list',
      description="List the docker images used by services",
      parents=[base_parser, services_parser])
  containers_list_parser.set_defaults(func=containers_list)

  containers_show_manifest_parser = containers_subparser.add_parser(
      'show-manifest',
      description="Print a json output of the docker containers by services",
      parents=[base_parser, services_parser])
  containers_show_manifest_parser.set_defaults(func=containers_show_manifest)

  # Deploy
  deployment_parser = main_subparsers.add_parser('deployment')
  deployment_subparser = deployment_parser.add_subparsers()

  # Args and manifest are shared by all deployment subcommands
  deployment_args_parser = argparse.ArgumentParser(add_help=False)
  deployment_args_parser.add_argument(
      '--manifest',
      action="store",
      required=True,
      help="path to the deployment manifest, built using `containers show-manifest`")
  deployment_args_parser.add_argument(
      '--args',
      metavar="KEY=VALUE",
      nargs='+',
      help="list of key/value pairs that define `expected-arg` in the deploy.yamls")

  deployment_diff_parser = deployment_subparser.add_parser(
      'diff',
      description="Diffs the deployment against the production deployment",
      parents=[base_parser, services_parser, deployment_args_parser])
  deployment_diff_parser.set_defaults(func=deployment_diff)

  deployment_dryrun_parser = deployment_subparser.add_parser(
      'dry-run',
      description="Tests whether the will deploy against the production deployment",
      parents=[base_parser, services_parser, deployment_args_parser])
  deployment_dryrun_parser.set_defaults(func=deployment_dry_run)

  return main_parser


##################################
# Main
##################################


def main():
  global should_debug
  global should_dry_run
  parser = create_arg_parser()
  args = parser.parse_args()
  should_debug = args.debug
  should_dry_run = args.dry_run
  args.func(args)


main()
