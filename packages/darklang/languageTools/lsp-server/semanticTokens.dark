// provides syntax highlighting
module Darklang =
  module LanguageTools =
    module LspServer =
      module SemanticTokens =
        /// note: these are referenced by their _index_!
        /// i.e. 'keyword' is 0, 'string' is 4, etc.
        let tokenTypes =
          [ "keyword" // for words 'let' and 'in'
            "function" // for function names/identifiers
            "parameter" // for function parameter identifiers
            "type" // for type names like Int, Bool, etc.
            "string" // for string literals
            "operator" // for operators like +, -
            "variable" ] // for general identifiers

        let tokenModifiers = []


        let hardcodedServerCapabilities
          ()
          : LanguageServerProtocol.SemanticTokens.SemanticTokenProviderOptions.SemanticTokenProviderOptions =
          LanguageServerProtocol
            .SemanticTokens
            .SemanticTokenProviderOptions
            .SemanticTokenProviderOptions
            .SemanticTokensOptions(
              LanguageServerProtocol.SemanticTokens.SemanticTokensOptions.SemanticTokensOptions
                { legend =
                    LanguageServerProtocol.SemanticTokens.SemanticTokensLegend.SemanticTokensLegend
                      { tokenTypes = tokenTypes
                        tokenModifiers = tokenModifiers }
                  range =
                    Stdlib.Option.Option.Some(
                      LanguageServerProtocol.SemanticTokens.SemanticTokensOptions.SemanticTokensOptionsRange.SemanticTokensOptionsRange.Bool
                        false
                    )
                  full =
                    Stdlib.Option.Option.Some(
                      LanguageServerProtocol.SemanticTokens.SemanticTokensOptions.SemanticTokensOptionsFull.SemanticTokensOptionsFull.Bool
                        true
                    ) }
            )

        let handleSemanticTokensRequest
          (state: LspState)
          (requestId: JsonRPC.RequestId)
          (_requestParams:
            LanguageServerProtocol.SemanticTokens.SemanticTokensRequest.SemanticTokensParams.SemanticTokensParams)
          : LspState =
          // TODO: prepare and return a 'real' response,
          // mapping from WrittenTypes
          let bogusResponse =
            LanguageServerProtocol
              .SemanticTokens
              .SemanticTokensRequest
              .SemanticTokensResult
              .SemanticTokensResult
              .SemanticTokens(
                LanguageServerProtocol.SemanticTokens.SemanticTokens.SemanticTokens
                  { resultId = Stdlib.Option.Option.None
                    data =
                      [
                        // Reported tokens are all in a big list of UInts -- five #s per reported token.
                        // The following translates to:

                        //                    the first token, ...
                        0UL // (deltaLine)      starts 0 lines after the previous token
                        0UL // (deltaStart)     starts 0 characters after the previous token
                        3UL // (length)         is 3 characters long
                        0UL // (tokenType)      is a keyword (in the `initialize` handshake, "keyword" is the 0th token type we declared)
                        0UL // (tokenModifiers) has no modifiers
                        //                      ^ _would_ be a bit-wise representation of the modifiers, but we have none

                        // (the .dark file that I've been testing against starts with the word `let` so this works out well)
                        ] }
              )

          let bogusResponseJson =
            bogusResponse
            |> LanguageServerProtocol.SemanticTokens.SemanticTokensRequest.SemanticTokensResult.toJson
            |> (fun r ->
              JsonRPC.Response.Ok.make (Stdlib.Option.Option.Some requestId) r)
            |> Stdlib.AltJson.format

          logAndSendToClient bogusResponseJson

          state


(*
// following are attempts at semantic-tree-ifying our parsed code, to be highlighted by VS Code

// v1 - this is ChatGPT-generated, largely, and is kinda broken but proved the point
// connection.onRequest(
//   SemanticTokensRequest.type,
//   ({ textDocument }): SemanticTokens => {
//     const tokens: number[] = [];
//     let lastLine = 0;
//     let lastStartChar = 0;

//     const encodeToken = (
//       line: number,
//       startChar: number,
//       length: number,
//       tokenType: number,
//     ) => {
//       const deltaLine = line - lastLine;
//       const deltaStart =
//         deltaLine === 0 ? startChar - lastStartChar : startChar;

//       tokens.push(deltaLine, deltaStart, length, tokenType, 0); // Assuming no tokenModifiers for simplicity

//       lastLine = line;
//       lastStartChar = startChar + length;
//     };

//     console.log("Processing semantic tokens request");

//     const content = documents.get(textDocument.uri)?.getText() || "";
//     const tree = parser.parse(content);

//     const processNode = (node: any) => {
//       //console.log("processing node", node);
//       const { type, startPosition, endPosition } = node;
//       const line = startPosition.row;
//       const startChar = startPosition.column;
//       const length = endPosition.column - startPosition.column;

//       switch (type) {
//         case "let":
//           encodeToken(line, startChar, length, 0);
//           break;

//         case "identifier":
//           if (
//             node.parent &&
//             node.parent.type === "fn_def" &&
//             node.parent.name === node
//           ) {
//             encodeToken(line, startChar, length, 1);
//           } else {
//             encodeToken(line, startChar, length, 6);
//           }
//           break;

//         case "fn_param_def":
//           encodeToken(line, startChar, length, 2);
//           break;

//         case "Int":
//         case "Bool":
//         case "Float":
//         case "String":
//         case "Char":
//           encodeToken(line, startChar, length, 3);
//           break;

//         case "string_literal":
//           encodeToken(line, startChar, length, 4);
//           break;

//         case "+":
//         case "-":
//           encodeToken(line, startChar, length, 5);
//           break;

//         default:
//           break;
//       }

//       // Recurse through child nodes
//       for (const child of node.children) {
//         processNode(child);
//       }
//     };

//     processNode(tree.rootNode);

//     console.log("Encoded tokens:", tokens);
//     return {
//       data: tokens,
//     };
//   },
// );

// v2: _manually_ returning the tokens that we want, for the exact code of:
//```
//let add (a: Int) (b: Int): Int =
//  let sum = a + b
//  sum
//```
connection.onRequest(
  SemanticTokensRequest.type,
  ({ textDocument }): SemanticTokens => {
    // our token types
    // | 0 | keyword   | words 'let' and 'in'            |
    // | 1 | function  | function names/identifiers      |
    // | 2 | parameter | function parameter identifiers  |
    // | 3 | type      | type names like Int, Bool, etc. |
    // | 4 | string    | string literals                 |
    // | 5 | operator  | operators like +, -             |
    // | 6 | variable  | general identifiers             |

    // code sample:
    // ```fsharp
    // let add (a: Int) (b: Int): Int =
    //   let sum = a + b
    //   sum
    // ```

    // | thing | ΔLine | ΔStart | length | type | modifier |
    // |-------|-------|--------|--------|------|----------|
    // | let   | 0     |      0 |      3 |    0 |        0 |
    // | add   | 0     |      1 |      3 |    6 |        0 |
    // | a     | ...   |        |        |      |          |
    // | Int   |       |        |        |      |          |
    // | b     |       |        |        |      |          |
    // | Int   |       |        |        |      |          |
    // | Int   |       |        |        |      |          |
    // | let   |       |        |        |      |          |
    // | sum   |       |        |        |      |          |
    // | a     |       |        |        |      |          |
    // | b     |       |        |        |      |          |
    // | sum   |       |        |        |      |          |
    // |       |       |        |        |      |          |

    // deltaLine: The difference in lines from the previous token.
    // deltaStart: The difference in characters (columns) from the previous token on the same line (or from the start of the line if it's the first token on that line).
    // length: The length of the token.
    // tokenType: The index in the token types array declared in the legend of the semantic token provider.
    // tokenModifiers: A bitset representing the token modifiers. Each bit of the value represents an index in the token modifiers array declared in the legend of the semantic token provider.

    // prettier-ignore
    const tokens =
      [ 0, 0, 3, 0, 0, // let
        0, 1, 3, 6, 0. // add
        // TODO: continue
      ]

    return {
      data: tokens,
    };
  },
);

// vFuture TODO: in a future pass, use this tree to replace all the below syntax-highlighting logic
// our parser includes a lot of things that _shouldn't_ be tokenized
// (like `fn_def`s which are really just wrappers around other tokens)
// , and the other tokens should use context such as "in a `fn_def`" to determine their type

// TODO: typescriptify this
// function simplifyTree(cursor: any): any {
//   let children = [];

//   if (cursor.gotoFirstChild()) {
//     do {
//       children.push(simplifyTree(cursor));
//     } while (cursor.gotoNextSibling());

//     cursor.gotoParent();
//   }

//   return {
//     typ: cursor.nodeType,
//     text: cursor.nodeText,
//     fieldName: cursor.currentFieldName(),
//     children: children,
//     startPosition: cursor.startPosition,
//     endPosition: cursor.endPosition,
//   };
// }
//
// connection.onRequest(
//   SemanticTokensRequest.type,
//   ({ textDocument }): SemanticTokens => {
//     console.log("Processing semantic tokens request");
//
//     const content = documents.get(textDocument.uri)?.getText() || "";
//     const tree = parser.parse(content);
//
//     let simpleTree = simplifyTree(tree.rootNode.walk());
//     console.log("simpletree", simpleTree);
//
//     // TODO: continue
//
//     return { data: [] };
//   },
// );
*)