module Darklang =
  module LanguageTools =
    /// This supports the Darklang-specific LSP (Language Server Protocol) server,
    /// per the 3.17 spec: https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification
    ///
    /// This LSP server is currently used by our in-progress VS Code Extension.
    /// Namely, `LspServer.runServerCli` creates a long-running process that reads
    /// incoming requests from stdin, and writes responses to stdout, following the LSP spec
    ///
    /// This depends on json-rpc 2.0 support, currently in the @Darklang.JsonRPC module
    ///
    /// TODO: some day, abstract out general LSP support in a separate module
    module LspServer =
      // <aliases>
      type Json = Stdlib.AltJson.Json
      // </aliases>


      type DocumentInScope = { uri: String; text: String }

      type State =
        {
          initialized: Bool

          shouldShutdown: Bool

          /// Documents that are currently open in the editor
          /// (i.e. have been `textDocument/didOpen`ed, and not yet `textDocument/didClose`d)
          /// note: the string key here is the URI
          documentsInScope: Dict<DocumentInScope>
        }

      let logFilePath = "/home/dark/app/rundir/logs/lsp-server.log"

      let log (input: String) : Unit =
        // returns Result -- ignored
        let _logged = Builtin.File.appendText logFilePath (input ++ "\n")

        ()

      let logRequest (request: String) : Unit = log $"From client: {request}"


      let logAndSendToClient (response: String) : Unit =
        log $"To client: {response}"

        let contentLengthInBytes =
          response
          |> Stdlib.String.toBytes_v0
          |> Stdlib.Bytes.length
          |> Stdlib.Int64.toString

        Builtin.print $"Content-Length: {contentLengthInBytes}\r\n\r\n{response}"


      // TODO maybe this should return a Result eventually,
      // and Error if we don't get a proper LSP message
      let readMessageFromClient () : String =
        Builtin.Danger.LanguageServerProtocol.readNextMessage ()


      let handleRequest (state: State) (r: JsonRPC.Request.Request) : State =
        match (r.method, r.id, r.params) with
        // -- Lifecycle and general support
        | ("initialize", None, _) ->
          log "TODO: fail - we shouldn't be seeing a second one of these"
          { state with initialized = true }

        | ("initialized", None, Some(Object [])) ->
          log "(ignore)"
          state

        | ("$/setTrace", None, _) ->
          log "TODO we should do something with this"
          state

        | ("shutdown", None, _) ->
          log "shutting down"
          { state with shouldShutdown = true }


        // -- textDocument synchronization
        | ("textDocument/didOpen", None, Some(Object fields)) ->
          // TODO: use `LanguageServerProtocol.DocumentSync.TextDocument.DidOpenTextDocumentNotification.method` above
          let reconstructedJson = Stdlib.AltJson.Json.Object fields

          let parsed =
            LanguageServerProtocol.DocumentSync.TextDocument.DidOpenTextDocumentNotification.DidOpenTextDocumentParams.fromJson
              reconstructedJson

          match parsed with
          | Ok parsed ->
            log $"adding/setting document {parsed.textDocument.uri}"

            { state with
                documentsInScope =
                  Stdlib.Dict.set
                    state.documentsInScope
                    parsed.textDocument.uri
                    parsed.textDocument.text }
          | Error() ->
            log "couldn't parse params of didOpen"
            state


        | ("textDocument/didSave", None, Some(Object fields)) ->
          // TODO: use `LanguageServerProtocol.DocumentSync.TextDocument.DidSaveTextDocumentNotification.method` above
          let reconstructedJson = Stdlib.AltJson.Json.Object fields

          let parsed =
            LanguageServerProtocol.DocumentSync.TextDocument.DidSaveTextDocumentNotification.DidSaveTextDocumentParams.fromJson
              reconstructedJson

          match parsed with
          | Ok parsed ->
            match parsed.text with
            | None ->
              log "WARNING: no text in didSave"
              state

            | Some text ->
              log $"updating document {parsed.textDocument.uri}"

              { state with
                  documentsInScope =
                    Stdlib.Dict.set
                      state.documentsInScope
                      parsed.textDocument.uri
                      text }
          | Error() ->
            log "couldn't parse params of didSave"
            state

        | ("textDocument/didClose", None, Some(Object fields)) ->
          // TODO: use `LanguageServerProtocol.DocumentSync.TextDocument.DidCloseTextDocumentNotification.method` above
          let reconstructedJson = Stdlib.AltJson.Json.Object fields

          let parsed =
            LanguageServerProtocol.DocumentSync.TextDocument.DidCloseTextDocumentNotification.DidCloseTextDocumentParams.fromJson
              reconstructedJson

          match parsed with
          | Ok parsed ->
            log $"removing document from documentsInScope"

            { state with
                documentsInScope =
                  Stdlib.Dict.remove state.documentsInScope parsed.textDocument.uri }
          | Error() ->
            log "couldn't parse params of didSave"
            state
        // -- textDocument
        | ("textDocument/didOpen", None) ->
          log "TODO we should do something with this - like report problems"
          false
        | ("textDocument/didSave", None) ->
          log "TODO we should do something with this - like report problems"
          false


        // -- other
        | (other, _, _) ->
          log $"TODO: we don't yet support this method: {other}"
          state


      let runServerCliLoop (state: State) : Int64 =
        log "---"

        let incomingMessageRaw = readMessageFromClient ()
        logRequest incomingMessageRaw


        let updatedState =
          match JsonRPC.IncomingMessage.parse incomingMessageRaw with
          // # Things we want/expect

          | SingleRequest(Ok(jsonRpcRequest)) ->
            log $"Parsed incoming message as single JSON-RPC request"
            handleRequest state jsonRpcRequest

          | BatchOfRequests items ->
            // TODO: need to reply in a batch as well
            log "TODO - Got batch request; not yet set to handle these"
            state


          // # Errors

          // was an object {} but not a valid json-rpc 2.0 _request_
          // (note: could have been a valid _response_ though - we don't yet have good support for that)
          | SingleRequest(Error(singleRequestParseError)) ->
            // TODO match on singleRequestParseError, and return proper error-specific responses

            log
              $"Error parsing incoming message as json-rpc request:\n{incomingMessageRaw}"

            logAndSendToClient
              """{"jsonrpc": "2.0", "error": {"code": -32700, "message": "Parse error"}, "id": null}"""

            state


          | NotJson ->
            log
              $"Error parsing incoming message as json:\n{incomingMessageRaw}\nError: {PACKAGE.Darklang.Stdlib.AltJson.ParseError.toString err}"

            logAndSendToClient
              """{"jsonrpc": "2.0", "error": {"code": -32700, "message": "Parse error"}, "id": null}"""

            state


          | NotObjectOrArray ->
            log $"Error parsing incoming message as json-rpc:\n{incomingMessageRaw}"

            logAndSendToClient
              """{"jsonrpc": "2.0", "error": {"code": -32600, "message": "Invalid Request"}, "id": null}"""

            state


          // The json-rpc spec says to just ignore any incoming messages of `[]`
          | EmptyBatch ->
            log "ignoring empty batch"
            state


        // shut down if instructed, or listen for the next message
        if updatedState.shouldShutdown then
          0L
        else
          runServerCliLoop updatedState



      let runServerCli (u: Unit) : Int64 =
        // clear `lsp.log`
        let _deleted = Builtin.File.delete logFilePath

        let nowStr =
          (PACKAGE.Darklang.Stdlib.DateTime.now_v0 ())
          |> PACKAGE.Darklang.Stdlib.DateTime.toString

        log $"Running Darklang LSP Server {nowStr}"


        // The first thing we get is the `"method": "initialize"` request,
        // which we need to respond to with the capabilities of the server
        //
        // At this point we are ignoring the body of this request, and just
        // responding with a static set of capabilities of the server
        //
        // https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#initialize
        let incomingMessageRaw = readMessageFromClient ()
        logRequest incomingMessageRaw // otherwise ignored...


        // Let's demonstrate that the server is waking up.
        // These are (basically) the only things we're allowed to do before
        // returning the initialize response
        logAndSendToClient
          """{ "jsonrpc": "2.0", "method": "$/logTrace", "params": { "message": "hi I'm an early trace" } }"""

        logAndSendToClient
          """{ "jsonrpc":"2.0", "method":"window/showMessage", "params":{"type":3,"message":"wow cool, a second message from the server came in"}}"""

        logAndSendToClient
          """{ "jsonrpc":"2.0", "method":"window/logMessage", "params":{"type":1,"message":"just logging a message"}}"""



        // finally, reply to the initialize request
        let initializeResult =
          LanguageServerProtocol.Lifecycle.InitializeRequest.InitializeResult.InitializeResult
            { capabilities =
                LanguageServerProtocol.Lifecycle.InitializeRequest.ServerCapabilities.ServerCapabilities
                  { textDocumentSync =
                      Stdlib.Option.Option.Some(
                        LanguageServerProtocol
                          .Lifecycle
                          .InitializeRequest
                          .TextDocumentSyncServerCapabilities
                          .TextDocumentSyncServerCapabilities
                          .TextDocumentSyncOptions(
                            LanguageServerProtocol.DocumentSync.TextDocument.TextDocumentSyncOptions.TextDocumentSyncOptions
                              { openClose = Stdlib.Option.Option.Some true
                                change =
                                  Stdlib.Option.Option.Some
                                    LanguageServerProtocol.DocumentSync.TextDocument.TextDocumentSyncKind.TextDocumentSyncKind.Full
                                save =
                                  Stdlib.Option.Option.Some(
                                    LanguageServerProtocol
                                      .DocumentSync
                                      .TextDocument
                                      .TextDocumentSyncOptions
                                      .SaveOptionsOrBool
                                      .SaveOptionsOrBool
                                      .SaveOptions(
                                        LanguageServerProtocol.DocumentSync.TextDocument.SaveOptions.SaveOptions
                                          { includeText =
                                              Stdlib.Option.Option.Some true }
                                      )
                                  ) }
                          )
                      ) }
              serverInfo = Stdlib.Option.Option.None }

        let initializeResponse =
          initializeResult
          |> LanguageServerProtocol.Lifecycle.InitializeRequest.InitializeResult.toJson
          |> (fun r -> JsonRPC.Response.Ok.make (Stdlib.Option.Option.Some 0L) r)
          |> Stdlib.AltJson.format

        logAndSendToClient initializeResponse


        let initialState =
          State
            { initialized = true
              shouldShutdown = false
              documentsInScope = Dict { } }

        // now that _that_ is out of the way, we can start responding to normal requests
        runServerCliLoop initialState





(* Some handy types

export type Position = { line: number; character: number };

export type Range = {
  start: Position;
  end_: Position;
};

export type DiagnosticSeverity = "Warning" | "Error";

export type Diagnostic = {
  severity: DiagnosticSeverity;
  range: Range;
  message: string;
};

export type ComputeDiagnosticsOutput = {
  diagnostics: Diagnostic[];
};

*)




(* future: report diagnostics on content update or save

async function gatherAndReportDiagnostics(
  textDocument: TextDocument,
): Promise<void> {
  const diagnosticsFromDarkResponse = await runDarkCli(
    "@PACKAGE.Darklang.LanguageTools.LanguageServerProtocol.getDiagnostics",
    textDocument.uri,
    JSON.stringify(textDocument.getText()),
  );

  if (diagnosticsFromDarkResponse.stderr) {
    console.error("stderr", diagnosticsFromDarkResponse.stderr);
  } else {
    console.log("got diagnostics back", diagnosticsFromDarkResponse.stdout);
    const diagnosticsFromDark: ComputeDiagnosticsOutput = JSON.parse(
      diagnosticsFromDarkResponse.stdout,
    );
    const diagnostics = diagnosticsFromDark.diagnostics.map(DT2LT.diagnostic);
    connection.sendDiagnostics({ uri: textDocument.uri, diagnostics });
  }
}

// when a document is changed or saved, we want to re-run diagnostics
let changeToProcessNext: null | TextDocumentChangeEvent<TextDocument> = null;
let processing = false;
const processChange = async () => {
  if (processing || !changeToProcessNext) return;
  processing = true;
  try {
    const doc = changeToProcessNext.document;
    changeToProcessNext = null;
    await gatherAndReportDiagnostics(doc);
  } finally {
    processing = false;
    if (changeToProcessNext) {
      processChange();
    }
  }
};
documents.onDidSave(change => {
  changeToProcessNext = change;
  processChange();
});
documents.onDidChangeContent(change => {
  changeToProcessNext = change;
  processChange();
});

*)




(* Future: completions (autocomplete)

include this in 'capabilities' configuration:

      completionProvider: {
        resolveProvider: true,
      },


// (how) should we autocomplete?
// (currently this just provides 2 bogus autocompletes)
connection.onCompletion(
  (_textDocumentPosition: TextDocumentPositionParams): CompletionItem[] => {
    return [
      { label: "TypeScript", kind: CompletionItemKind.Text, data: 1 },
      { label: "JavaScript", kind: CompletionItemKind.Text, data: 2 },
    ];
  },
);

// once you hover over some completion, this fills in some details (I think)
connection.onCompletionResolve((item: CompletionItem): CompletionItem => {
  if (item.data === 1) {
    item.detail = "TypeScript details";
    item.documentation = "TypeScript documentation";
  } else if (item.data === 2) {
    item.detail = "JavaScript details";
    item.documentation = "JavaScript documentation";
  }
  return item;
});

*)




(* Future: syntax highlighting via darklang:

// TODO share across server/client, if relevant?
// or generate these from Darklang code?
//
// note: these are referenced by their _index_!
// i.e. 'keyword' is 0, 'string' is 4, etc.
const tokenTypes = [
  "keyword", // for words 'let' and 'in'
  "function", // for function names/identifiers
  "parameter", // for function parameter identifiers
  "type", // for type names like Int, Bool, etc.
  "string", // for string literals
  "operator", // for operators like +, -
  "variable", // for general identifiers
];
const tokenModifiers: string[] = [];


during 'initialize' handshake, include this in 'capabilities' configuration:

      semanticTokensProvider: {
        legend: {
          tokenTypes: tokenTypes,
          tokenModifiers: tokenModifiers,
        },
        range: false,
        full: {
          delta: false,
        },
      },




// following are attempts at semantic-tree-ifying our parsed code, to be highlighted by VS Code

// v1 - this is ChatGPT-generated, largely, and is kinda broken but proved the point
// connection.onRequest(
//   SemanticTokensRequest.type,
//   ({ textDocument }): SemanticTokens => {
//     const tokens: number[] = [];
//     let lastLine = 0;
//     let lastStartChar = 0;

//     const encodeToken = (
//       line: number,
//       startChar: number,
//       length: number,
//       tokenType: number,
//     ) => {
//       const deltaLine = line - lastLine;
//       const deltaStart =
//         deltaLine === 0 ? startChar - lastStartChar : startChar;

//       tokens.push(deltaLine, deltaStart, length, tokenType, 0); // Assuming no tokenModifiers for simplicity

//       lastLine = line;
//       lastStartChar = startChar + length;
//     };

//     console.log("Processing semantic tokens request");

//     const content = documents.get(textDocument.uri)?.getText() || "";
//     const tree = parser.parse(content);

//     const processNode = (node: any) => {
//       //console.log("processing node", node);
//       const { type, startPosition, endPosition } = node;
//       const line = startPosition.row;
//       const startChar = startPosition.column;
//       const length = endPosition.column - startPosition.column;

//       switch (type) {
//         case "let":
//           encodeToken(line, startChar, length, 0);
//           break;

//         case "identifier":
//           if (
//             node.parent &&
//             node.parent.type === "fn_def" &&
//             node.parent.name === node
//           ) {
//             encodeToken(line, startChar, length, 1);
//           } else {
//             encodeToken(line, startChar, length, 6);
//           }
//           break;

//         case "fn_param_def":
//           encodeToken(line, startChar, length, 2);
//           break;

//         case "Int":
//         case "Bool":
//         case "Float":
//         case "String":
//         case "Char":
//           encodeToken(line, startChar, length, 3);
//           break;

//         case "string_literal":
//           encodeToken(line, startChar, length, 4);
//           break;

//         case "+":
//         case "-":
//           encodeToken(line, startChar, length, 5);
//           break;

//         default:
//           break;
//       }

//       // Recurse through child nodes
//       for (const child of node.children) {
//         processNode(child);
//       }
//     };

//     processNode(tree.rootNode);

//     console.log("Encoded tokens:", tokens);
//     return {
//       data: tokens,
//     };
//   },
// );

// v2: _manually_ returning the tokens that we want, for the exact code of:
//```
//let add (a: Int) (b: Int): Int =
//  let sum = a + b
//  sum
//```
connection.onRequest(
  SemanticTokensRequest.type,
  ({ textDocument }): SemanticTokens => {
    // our token types
    // | 0 | keyword   | words 'let' and 'in'            |
    // | 1 | function  | function names/identifiers      |
    // | 2 | parameter | function parameter identifiers  |
    // | 3 | type      | type names like Int, Bool, etc. |
    // | 4 | string    | string literals                 |
    // | 5 | operator  | operators like +, -             |
    // | 6 | variable  | general identifiers             |

    // code sample:
    // ```fsharp
    // let add (a: Int) (b: Int): Int =
    //   let sum = a + b
    //   sum
    // ```

    // | thing | ΔLine | ΔStart | length | type | modifier |
    // |-------|-------|--------|--------|------|----------|
    // | let   | 0     |      0 |      3 |    0 |        0 |
    // | add   | 0     |      1 |      3 |    6 |        0 |
    // | a     | ...   |        |        |      |          |
    // | Int   |       |        |        |      |          |
    // | b     |       |        |        |      |          |
    // | Int   |       |        |        |      |          |
    // | Int   |       |        |        |      |          |
    // | let   |       |        |        |      |          |
    // | sum   |       |        |        |      |          |
    // | a     |       |        |        |      |          |
    // | b     |       |        |        |      |          |
    // | sum   |       |        |        |      |          |
    // |       |       |        |        |      |          |

    // deltaLine: The difference in lines from the previous token.
    // deltaStart: The difference in characters (columns) from the previous token on the same line (or from the start of the line if it's the first token on that line).
    // length: The length of the token.
    // tokenType: The index in the token types array declared in the legend of the semantic token provider.
    // tokenModifiers: A bitset representing the token modifiers. Each bit of the value represents an index in the token modifiers array declared in the legend of the semantic token provider.

    // prettier-ignore
    const tokens =
      [ 0, 0, 3, 0, 0, // let
        0, 1, 3, 6, 0. // add
        // TODO: continue
      ]

    return {
      data: tokens,
    };
  },
);

// vFuture TODO: in a future pass, use this tree to replace all the below syntax-highlighting logic
// our parser includes a lot of things that _shouldn't_ be tokenized
// (like `fn_def`s which are really just wrappers around other tokens)
// , and the other tokens should use context such as "in a `fn_def`" to determine their type

// TODO: typescriptify this
// function simplifyTree(cursor: any): any {
//   let children = [];

//   if (cursor.gotoFirstChild()) {
//     do {
//       children.push(simplifyTree(cursor));
//     } while (cursor.gotoNextSibling());

//     cursor.gotoParent();
//   }

//   return {
//     typ: cursor.nodeType,
//     text: cursor.nodeText,
//     fieldName: cursor.currentFieldName(),
//     children: children,
//     startPosition: cursor.startPosition,
//     endPosition: cursor.endPosition,
//   };
// }
//
// connection.onRequest(
//   SemanticTokensRequest.type,
//   ({ textDocument }): SemanticTokens => {
//     console.log("Processing semantic tokens request");
//
//     const content = documents.get(textDocument.uri)?.getText() || "";
//     const tree = parser.parse(content);
//
//     let simpleTree = simplifyTree(tree.rootNode.walk());
//     console.log("simpletree", simpleTree);
//
//     // TODO: continue
//
//     return { data: [] };
//   },
// );


*)