module OpenAI =

  module Config =
    let apiKey = "openai-api-key"

    let getHeaders () : List<(String * String)> =
      [ ("authorization", "Bearer " ++ PACKAGE.OpenAI.Config.apiKey)
        ("content-type", "application/json") ]

  module Completion =
    type Request =
      { model: String
        prompt: String
        max_tokens: Int64
        temperature: Float }

    type ResponseChoice = { text: String }

    type Response =
      { id: String
        object: String
        created: Int64
        model: String
        choices: List<ResponseChoice> }

    let completion (prompt: String) : Darklang.Stdlib.Result.Result<String, String> =
      let openAIRequest =
        Request
          { model = "text-davinci-003"
            prompt = prompt
            max_tokens = 700L
            temperature = 0.7 }

      let reqBody = Builtin.Json.serialize<Request> openAIRequest

      let headers = Config.getHeaders ()

      let openAIResponse =
        Darklang.Stdlib.HttpClient.request
          "POST"
          "https://api.openai.com/v1/completions"
          headers
          (Darklang.Stdlib.String.toBytes reqBody)

      match openAIResponse with
      | Ok r ->
        match
          Builtin.Json.parse<Response> (
            Darklang.Stdlib.String.fromBytesWithReplacement r.body
          )
        with
        | Ok r ->
          match Darklang.Stdlib.List.head r.choices with
          | Some c -> Darklang.Stdlib.Result.Result.Ok c.text
          | None -> Darklang.Stdlib.Result.Result.Error "No choices returned"
      | Error err ->
        Darklang.Stdlib.Result.Result.Error(
          "Couldn't parse OpenAI completion response - " ++ err
        )


  module ChatCompletion =
    type RequestMessage = { role: String; content: String }

    type Request =
      { model: String
        max_tokens: Int64
        temperature: Float
        messages: List<RequestMessage> }

    type ResponseChoiceMessage = { content: String }
    type ResponseChoice = { message: ResponseChoiceMessage }
    type Response = { choices: List<ResponseChoice> }


    type CompletionOptions =
      { model: String
        messages: List<RequestMessage>
        temperature: Float
        max_tokens: Int64
        top_p: Float
        n: Int64
        stream: Bool }

    let completionOptionsDefault () : CompletionOptions =
      CompletionOptions
        { model = "gpt-3.5-turbo"
          messages = [ RequestMessage { role = "user"; content = "test" } ]
          temperature = 0.7
          max_tokens = 700L
          top_p = 1.0
          n = 1L
          stream = false }


    let completionWithOption
      (prompt: String)
      (options: Darklang.Stdlib.Option.Option<CompletionOptions>)
      : Darklang.Stdlib.Result.Result<String, String> =
      let options =
        match options with
        | Some o ->
          { o with
              messages = [ RequestMessage { role = "user"; content = prompt } ] }
        | None ->
          { (completionOptionsDefault ()) with
              messages = [ RequestMessage { role = "user"; content = prompt } ] }

      let openAIRequest = options

      let reqBody = Builtin.Json.serialize<CompletionOptions> openAIRequest

      let headers = Config.getHeaders ()

      let openAIResponse =
        Darklang.Stdlib.HttpClient.request
          "POST"
          "https://api.openai.com/v1/chat/completions"
          headers
          (Darklang.Stdlib.String.toBytes reqBody)

      match openAIResponse with
      | Ok r ->
        match
          Builtin.Json.parse<Response> (
            Darklang.Stdlib.String.fromBytesWithReplacement r.body
          )
        with
        | Ok r ->
          match Darklang.Stdlib.List.head r.choices with
          | Some c -> Darklang.Stdlib.Result.Result.Ok c.message.content
          | None -> Darklang.Stdlib.Result.Result.Error "No choices returned"
        | Error err ->
          Darklang.Stdlib.Result.Result.Error(
            "Couldn't parse OpenAI completion response - " ++ err
          )
      | Error e ->
        Darklang.Stdlib.Result.Result.Error("OpenAI API request failed\n" ++ e)



    let completion (prompt: String) : Darklang.Stdlib.Result.Result<String, String> =
      let openAIRequest =
        Request
          { model = "gpt-3.5-turbo"
            max_tokens = 700L
            temperature = 0.7
            messages = [ RequestMessage { role = "user"; content = prompt } ] }

      let reqBody = Builtin.Json.serialize<Request> openAIRequest

      let headers = PACKAGE.OpenAI.Config.getHeaders ()

      let openAIResponse =
        Darklang.Stdlib.HttpClient.request
          "POST"
          "https://api.openai.com/v1/chat/completions"
          headers
          (Darklang.Stdlib.String.toBytes reqBody)

      match openAIResponse with
      | Ok r ->
        match
          Builtin.Json.parse<Response> (
            Darklang.Stdlib.String.fromBytesWithReplacement r.body
          )
        with
        | Ok r ->
          match Darklang.Stdlib.List.head r.choices with
          | Some c -> Darklang.Stdlib.Result.Result.Ok c.message.content
          | None -> Darklang.Stdlib.Result.Result.Error "No choices returned"
        | Error err ->
          Darklang.Stdlib.Result.Result.Error(
            "Couldn't parse OpenAI completion response - " ++ err
          )
      | Error e ->
        Darklang.Stdlib.Result.Result.Error("OpenAI API request failed\n" ++ e)


  module ImageGeneration =
    type Request = { prompt: String; size: String }

    type ResponseData = { url: String }
    type Response = { data: List<ResponseData> }

    /// Returns a url to the image
    ///
    /// CLEANUP should it return the image itself instead?
    let imageGeneration
      (prompt: String)
      : Darklang.Stdlib.Result.Result<String, String> =

      let openAIRequest = Request { prompt = prompt; size = "256x256" }

      let reqBody = Builtin.Json.serialize<Request> openAIRequest

      let headers = Config.getHeaders ()

      let openAIResponse =
        Darklang.Stdlib.HttpClient.request
          "POST"
          "https://api.openai.com/v1/images/generations"
          headers
          (Darklang.Stdlib.String.toBytes reqBody)

      match openAIResponse with
      | Ok r ->
        match
          Builtin.Json.parse<Response> (
            Darklang.Stdlib.String.fromBytesWithReplacement r.body
          )
        with
        | Ok r ->
          match Darklang.Stdlib.List.head r.data with
          | Some d -> Darklang.Stdlib.Result.Result.Ok d.url
          | None -> Darklang.Stdlib.Result.Result.Error "No data returned"
        | Error err ->
          Darklang.Stdlib.Result.Result.Error(
            "Couldn't parse open ai image generation response - " ++ err
          )
      | Error e ->
        Darklang.Stdlib.Result.Result.Error("OpenAI API request failed\n" ++ e)


  module Model =
    type Request = { model: String }

    type Response =
      { id: String
        object: String
        created: Int64
        model: String }


    let retrieveModel
      (model: String)
      : Darklang.Stdlib.Result.Result<String, String> =

      let headers = Config.getHeaders ()

      let modelResponse =
        Darklang.Stdlib.HttpClient.request
          "GET"
          $"https://api.openai.com/v1/models/{model}"
          headers
          []

      match modelResponse with
      | Ok r ->
        r.body
        |> Darklang.Stdlib.String.fromBytesWithReplacement
        |> Darklang.Stdlib.Result.Result.Ok
      | Error e ->
        Darklang.Stdlib.Result.Result.Error("OpenAI API request failed\n" ++ e)


    let getListOfModels () : Darklang.Stdlib.Result.Result<List<String>, String> =
      let modelResponse =
        Darklang.Stdlib.HttpClient.request
          "GET"
          "https://api.openai.com/v1/models"
          (Config.getHeaders ())
          []

      match modelResponse with
      | Ok r ->
        r.body
        |> Darklang.Stdlib.String.fromBytesWithReplacement
        |> Darklang.Stdlib.Result.Result.Ok
      | Error e ->
        Darklang.Stdlib.Result.Result.Error("OpenAI API request failed\n" ++ e)